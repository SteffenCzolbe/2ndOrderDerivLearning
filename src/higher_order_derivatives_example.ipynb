{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch                                                                                          \n",
    "                                                                                                      \n",
    "def jacobian(y, x, create_graph=False):                                                               \n",
    "    jac = []                                                                                          \n",
    "    flat_y = y.reshape(-1)                                                                            \n",
    "    grad_y = torch.zeros_like(flat_y)  \n",
    "    # for each function output\n",
    "    for i in range(len(flat_y)):                                                                      \n",
    "        grad_y[i] = 1.                                                                                \n",
    "        grad_x, = torch.autograd.grad(flat_y, x, grad_y, retain_graph=True, create_graph=create_graph)\n",
    "        jac.append(grad_x.reshape(x.shape))                                                           \n",
    "        grad_y[i] = 0.                                                                                \n",
    "    return torch.stack(jac).reshape(y.shape + x.shape)                                                \n",
    "                                                                                                      \n",
    "def hessian(y, x):                                                                                    \n",
    "    return jacobian(jacobian(y, x, create_graph=True), x)                                             \n",
    "                                                                                                      \n",
    "def f(x):                                                                                             \n",
    "    return x * x * torch.arange(4, dtype=torch.float)   \n",
    "\n",
    "def rosenbrock(x):\n",
    "    assert len(x) == 2\n",
    "    return (1 - x[0])**2 + 100*(x[1] - x[0]**2)**2 \n",
    "\n",
    "def rosenbrock_jacobian(x):\n",
    "    return torch.tensor([\n",
    "        -400*x[0]*x[1] + 400*x[0]**3+2*x[0]-2,\n",
    "        200*x[1] - 200 * x[0]\n",
    "    ])\n",
    "def rosenbrock_hessian(x):\n",
    "    return torch.tensor([\n",
    "        [-400 * x[1] + 1200* x[0]**3 + 2,   -400*x[0]],\n",
    "        [-400*x[0]                      , 200]\n",
    "    ])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analytical grad: tensor([-2.,  0.])\n",
      "autograd grad: tensor([-2.,  0.])\n",
      "analytical hess: tensor([[  2.,  -0.],\n",
      "        [ -0., 200.]])\n",
      "autograd hess: tensor([[  2.,   0.],\n",
      "        [  0., 200.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([0., 0.], requires_grad=True)  \n",
    "y = rosenbrock(x)\n",
    "\n",
    "print('analytical grad:', rosenbrock_jacobian(x))\n",
    "print('autograd grad:', jacobian(y, x))\n",
    "\n",
    "print('analytical hess:', rosenbrock_hessian(x))\n",
    "print('autograd hess:', hessian(y, x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
